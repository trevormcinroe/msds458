{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from textattack.augmentation import EmbeddingAugmenter, EasyDataAugmenter\n",
    "import numpy as np\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"LOADING DATA\"\"\"\n",
    "file = open('./data/semeval.txt', 'r')\n",
    "headers = file.readline().split('\\t')\n",
    "\n",
    "file = open('./data/semeval.txt', 'r')\n",
    "data = list()\n",
    "for line in file:\n",
    "    data.append(line.split('\\t'))\n",
    "data = data[1:]\n",
    "\n",
    "data = pd.DataFrame(data, columns=headers)\n",
    "data['relatedness_score'] = pd.to_numeric(data['relatedness_score'])\n",
    "\n",
    "file = open('./data/semeval_train.txt', 'r')\n",
    "headers = file.readline().split('\\t')\n",
    "\n",
    "file = open('./data/semeval_train.txt', 'r')\n",
    "data_train = list()\n",
    "for line in file:\n",
    "    data_train.append(line.split('\\t'))\n",
    "data_train = data_train[1:]\n",
    "\n",
    "data_train = pd.DataFrame(data_train, columns=headers)\n",
    "data_train['relatedness_score'] = pd.to_numeric(data_train['relatedness_score'])\n",
    "data_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.iloc[:len(data)-1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aug 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for i in range(len(data_train)):\n",
    "    for _ in range(3):\n",
    "        s1 = data_train['sentence_A'][i]\n",
    "        s2 = data_train['sentence_B'][i]\n",
    "        score = data_train['relatedness_score'][i]\n",
    "\n",
    "        s1 = aug.augment(s1)\n",
    "        s2 = aug.augment(s2)\n",
    "\n",
    "        sentences.append([s1, s2, score])\n",
    "        \n",
    "pd.DataFrame(sentences, columns=['sent_1', 'sent_2', 'sim']).to_csv('./data/semeval_train_aug.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for i in range(len(data)):\n",
    "    for _ in range(3):\n",
    "        s1 = data['sentence_A'][i]\n",
    "        s2 = data['sentence_B'][i]\n",
    "        score = data['relatedness_score'][i]\n",
    "\n",
    "        s1 = aug.augment(s1)\n",
    "        s2 = aug.augment(s2)\n",
    "\n",
    "        sentences.append([s1, s2, score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(sentences, columns=['sent_1', 'sent_2', 'sim']).to_csv('./data/semeval_test_aug.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aug 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_aug = EmbeddingAugmenter()\n",
    "easy_aug = EasyDataAugmenter()\n",
    "\n",
    "sentences = []\n",
    "for i in range(len(data_train)):\n",
    "    s1 = data_train['sentence_A'][i]\n",
    "    s2 = data_train['sentence_B'][i]\n",
    "    score = data_train['relatedness_score'][i]\n",
    "\n",
    "    easy_sentences1 = easy_aug.augment(s1)\n",
    "    easy_sentences2 = easy_aug.augment(s2)\n",
    "    \n",
    "#     embed_sentences1 = list()\n",
    "#     embed_sentences2 = list()\n",
    "    \n",
    "#     for _ in range(3):\n",
    "#         embed_sentences1.append(embed_aug.augment(s1)[0])\n",
    "#         embed_sentences2.append(embed_aug.augment(s2)[0])\n",
    "        \n",
    "    for j in range(len(easy_sentences1)):\n",
    "        sentences.append([easy_sentences1[j], easy_sentences2[j], score])\n",
    "        \n",
    "#     for k in range(len(embed_sentences1)):\n",
    "#         sentences.append([embed_sentences1[k], embed_sentences2[k], score])\n",
    "\n",
    "pd.DataFrame(sentences, columns=['sent_1', 'sent_2', 'sim']).to_csv('./data/semeval_train_aug.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_aug = EmbeddingAugmenter()\n",
    "easy_aug = EasyDataAugmenter()\n",
    "\n",
    "sentences = []\n",
    "for i in range(len(data)):\n",
    "    s1 = data['sentence_A'][i]\n",
    "    s2 = data['sentence_B'][i]\n",
    "    score = data['relatedness_score'][i]\n",
    "\n",
    "    easy_sentences1 = easy_aug.augment(s1)\n",
    "    easy_sentences2 = easy_aug.augment(s2)\n",
    "    \n",
    "#     embed_sentences1 = list()\n",
    "#     embed_sentences2 = list()\n",
    "    \n",
    "#     for _ in range(3):\n",
    "#         embed_sentences1.append(embed_aug.augment(s1)[0])\n",
    "#         embed_sentences2.append(embed_aug.augment(s2)[0])\n",
    "        \n",
    "    for j in range(len(easy_sentences1)):\n",
    "        sentences.append([easy_sentences1[j], easy_sentences2[j], score])\n",
    "        \n",
    "#     for k in range(len(embed_sentences1)):\n",
    "#         sentences.append([embed_sentences1[k], embed_sentences2[k], score])\n",
    "\n",
    "pd.DataFrame(sentences, columns=['sent_1', 'sent_2', 'sim']).to_csv('./data/semeval_test_aug.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aug 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "translator = Translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list()\n",
    "\n",
    "for i in tqdm.tqdm(range(len(data_train))):\n",
    "    sentence1 = data_train['sentence_A'][i]\n",
    "    sentence2 = data_train['sentence_B'][i]\n",
    "    score = data_train['relatedness_score'][i]\n",
    "    \n",
    "    # To KO\n",
    "    ko_result1 = translator.translate(sentence1, src='en', dest='ko').text\n",
    "    ko_result2 = translator.translate(sentence2, src='en', dest='ko').text\n",
    "    \n",
    "    # And back\n",
    "    en_result1 = translator.translate(ko_result1, src='ko', dest='en').text\n",
    "    en_result2 = translator.translate(ko_result2, src='ko', dest='en').text\n",
    "    \n",
    "    sentences.append([en_result1, en_result2, score])\n",
    "    \n",
    "pd.DataFrame(sentences, columns=['sent_1', 'sent_2', 'sim']).to_csv('./data/semeval_train_ko.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list()\n",
    "\n",
    "for i in tqdm.tqdm(range(len(data))):\n",
    "    sentence1 = data['sentence_A'][i]\n",
    "    sentence2 = data['sentence_B'][i]\n",
    "    score = data['relatedness_score'][i]\n",
    "    \n",
    "    # To KO\n",
    "    ko_result1 = translator.translate(sentence1, src='en', dest='ko').text\n",
    "    ko_result2 = translator.translate(sentence2, src='en', dest='ko').text\n",
    "    \n",
    "    # And back\n",
    "    en_result1 = translator.translate(ko_result1, src='ko', dest='en').text\n",
    "    en_result2 = translator.translate(ko_result2, src='ko', dest='en').text\n",
    "    \n",
    "    sentences.append([en_result1, en_result2, score])\n",
    "    \n",
    "# pd.DataFrame(sentences, columns=['sent_1', 'sent_2', 'sim']).to_csv('./data/semeval_test_ko.csv', index=False)\n",
    "df.to_csv('./data/semeval_train_ko.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Occasionally, the API doesn't actually translate...\n",
    "sent1_idx = list()\n",
    "sent2_idx = list()\n",
    "for i in range(len(df)):\n",
    "    if 'e' not in df['sent_1'][i].lower():\n",
    "        if 'a' not in df['sent_1'][i].lower():\n",
    "            if 'i' not in df['sent_1'][i].lower():\n",
    "                if 'o' not in df['sent_1'][i].lower():\n",
    "                    sent1_idx.append(i)\n",
    "    if 'e' not in df['sent_2'][i].lower():\n",
    "        if 'a' not in df['sent_2'][i].lower():\n",
    "            if 'i' not in df['sent_2'][i].lower():\n",
    "                 if 'o' not in df['sent_2'][i].lower():\n",
    "                    sent2_idx.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1_fix = list()\n",
    "for idx in sent1_idx:\n",
    "    sent1_fix.append(translator.translate(df['sent_1'][idx], src='ko', dest='en').text)\n",
    "#     time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent2_fix = list()\n",
    "for idx in sent2_idx:\n",
    "    sent2_fix.append(translator.translate(df['sent_2'][idx], src='ko', dest='en').text)\n",
    "#     time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
